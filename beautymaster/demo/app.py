import sys
import os
import torch
import asyncio
from PIL import Image
import gradio as gr

sys.path.append(os.environ.get('CODE_ROOT')+'BeautyMaster/')
from beautymaster.demo.infer import Interface, parse_opt


vlm_weight_name = '/InternVL-Chat-V1-5-AWQ/'
llm_weight_name = '/internlm2-chat-20b-4bits/'
vlm_weight_name = '/Mini-InternVL-Chat-2B-V1-5-AWQ/'
vlm_weight_name = '/MiniCPM-Llama3-V-2_5-AWQ/'
llm_weight_name = '/Qwen2-7B-Instruct-AWQ/'

# vlm_weight_name = 'InternVL2-8B-AWQ/'
# llm_weight_name = 'internlm2_5-7b-chat/'
# llm_weight_name = 'internlm2_5-7b-chat-4bit'
# llm_weight_name = "Yi-1.5-6B-Chat"

if os.environ.get('openxlab'):

    base_path = os.environ.get('CODE_ROOT')+"BeautyMaster/"
    os.system(f'git clone --recursive -b openxlab-demo https://github.com/RayTang88/BeautyMaster.git {base_path}')
            
    # base_path = os.environ.get('MODEL_ROOT')+"lmdeploy_0-4-2_cpm_v2-5/"
    # os.system(f'git clone https://code.openxlab.org.cn/raytang88/lmdeploy_0-4-2_cpm_v2-5.git {base_path}')
    # os.system(f'cd {base_path} && git lfs pull')
    # package_path = base_path + "lmdeploy-0.4.2-cp310-cp310-manylinux2014_x86_64.whl"
    # os.system(f"pip install {package_path} -i https://pypi.tuna.tsinghua.edu.cn/simple")
    # os.system(f"cd {os.environ.get('CODE_ROOT')}")

    base_path = os.environ.get('MODEL_ROOT')+"Qwen2-7B-Instruct-AWQ/"
    os.system(f'git clone https://code.openxlab.org.cn/raytang88/Qwen2-7B-Instruct-AWQ.git {base_path}')
    os.system(f'cd {base_path} && git lfs pull')
    os.system(f"cd {os.environ.get('CODE_ROOT')}")

    base_path = os.environ.get('MODEL_ROOT')+"MiniCPM-Llama3-V-2_5-AWQ/"
    os.system(f'git clone https://code.openxlab.org.cn/raytang88/MiniCPM-Llama3-V-2_5-AWQ.git {base_path}')
    os.system(f'cd {base_path} && git lfs pull')
    os.system(f"cd {os.environ.get('CODE_ROOT')}")
    
    # base_path = os.environ.get('MODEL_ROOT')+"Mini-InternVL-Chat-2B-V1-5-AWQ/"
    # os.system(f'git clone https://code.openxlab.org.cn/raytang88/Mini-InternVL-Chat-2B-V1-5-AWQ.git {base_path}')
    # os.system(f'cd {base_path} && git lfs pull')
    # os.system(f"cd {os.environ.get('CODE_ROOT')}")

    base_path = os.environ.get('MODEL_ROOT')+"bce-embedding-base_v1/"
    os.system(f'git clone https://code.openxlab.org.cn/raytang88/bce-embedding-base_v1.git {base_path}')
    os.system(f'cd {base_path} && git lfs pull')

    base_path = os.environ.get('MODEL_ROOT')+"bce-reranker-base_v1/"
    os.system(f'git clone https://code.openxlab.org.cn/raytang88/bce-reranker-base_v1.git {base_path}')
    os.system(f'cd {base_path} && git lfs pull')
    os.system(f"cd {os.environ.get('CODE_ROOT')}")
    
    base_path = os.environ.get('MODEL_ROOT')+"CatVTON/"
    os.system(f'git clone https://code.openxlab.org.cn/raytang88/CatVTON.git {base_path}')
    os.system(f'cd {base_path} && git lfs pull')
    os.system(f"cd {os.environ.get('CODE_ROOT')}")
    
    #densepose
    os.system(f'pip install git+https://github.com/facebookresearch/detectron2@main#subdirectory=projects/DensePose')

    # vlm_weight_name = '/Mini-InternVL-Chat-2B-V1-5-AWQ/'
    vlm_weight_name = '/MiniCPM-Llama3-V-2_5-AWQ/'
    llm_weight_name = '/Qwen2-7B-Instruct-AWQ/'
    
    # vlm_weight_name = 'InternVL2-2B-AWQ/'
    # llm_weight_name = 'internlm2_5-7b-chat-4bit'

    
    # opt = parse_opt(vlm_weight_name, llm_weight_name)
    # interface = Interface(**vars(opt))

def set_image(match_reslult, idx):
    clothes_img_A = Image.new("RGB", (500, 300), 'white')
    clothes_img_B = Image.new("RGB", (500, 300), 'white')
    match_reason = ""
    if(len(match_reslult[idx]["images"])==1):
        clothes_img_A = match_reslult[idx]["images"][0]
    elif(len(match_reslult[idx]["images"])==2):
        clothes_img_A = match_reslult[idx]["images"][0]
        clothes_img_B = match_reslult[idx]["images"][1]
    match_reason = match_reslult[idx]["match_reason"]

    return clothes_img_A, clothes_img_B, match_reason

def set_image_try_on(match_reslult, idx):
    clothes_img_A = Image.new("RGB", (500, 300), 'white')
    clothes_img_B = Image.new("RGB", (500, 300), 'white')
    match_reason = ""
    if(len(match_reslult[idx]["images"])==1):
        clothes_img_A = match_reslult[idx]["images"][0]
    elif(len(match_reslult[idx]["images"])==2):
        clothes_img_A = match_reslult[idx]["images"][0]
        clothes_img_B = match_reslult[idx]["images"][1]
    match_reason = match_reslult[idx]["match_reason"]
    try_on_img = match_reslult[idx]["tryon_image"]
    return clothes_img_A, clothes_img_B, match_reason, try_on_img

# def set_image_try_on(match_reslult, idx):
    
#     try_on_img = match_reslult[idx]["tryon_image"]
    
#     return try_on_img


def cc(image):
    if image.mode in ('RGBA', 'LA'):
        image = image.convert('RGB')
    elif image.mode in ('RGB'):
        image = image
    else:
        print("unkown mode", image.mode)   
    return image

# async def reset_local_func(instruction_txtbox: gr.Textbox,
#                            state_chatbot: Sequence, session_id: int):
#     """reset the session.

#     Args:
#         instruction_txtbox (str): user's prompt
#         state_chatbot (Sequence): the chatting history
#         session_id (int): the session id
#     """
#     with interface.lock:
#         interface.global_session_id += 1
#     session_id = interface.global_session_id
#     await asyncio.sleep(0)
#     return (state_chatbot, state_chatbot, instruction_txtbox, session_id)

def run_local_match(weather, season, determine, additional_requirements, full_body_image):
    # opt = parse_opt(vlm_weight_name, llm_weight_name)
    # interface = Interface(**vars(opt))

    #RGBA-RGB
    planA_clothes_img_A = Image.new("RGB", (500, 300), 'white')
    planA_clothes_img_B = Image.new("RGB", (500, 300), 'white')
    planB_clothes_img_A = Image.new("RGB", (500, 300), 'white')
    planB_clothes_img_B = Image.new("RGB", (500, 300), 'white')
    # planC_clothes_img_A = Image.new("RGB", (500, 300), 'white')
    # planC_clothes_img_B = Image.new("RGB", (500, 300), 'white')
    
    planA_match_reason = ""
    planB_match_reason = ""
    # planC_match_reason = ""
    
    # print("full_body_image mode-------------", full_body_image["composite"].mode)
    full_body_image = cc(full_body_image["composite"])
    # print("full_body_image mode-------------", full_body_image.mode)
    
    match_result, body_shape_descs = interface.match_interface(weather,
    season,
    determine,
    full_body_image,
    additional_requirements)
    
    if len(match_result)==3:
        planA_clothes_img_A, planA_clothes_img_B, planA_match_reason = set_image(match_result, 0)
        planB_clothes_img_A, planB_clothes_img_B, planB_match_reason = set_image(match_result, 1)
        # planC_clothes_img_A, planC_clothes_img_B, planC_match_reason = set_image(match_reslult, 2)
  
    elif len(match_result)==2:
        planA_clothes_img_A, planA_clothes_img_B, planA_match_reason = set_image(match_result, 0)
        planB_clothes_img_A, planB_clothes_img_B, planB_match_reason = set_image(match_result, 1)
        
    elif len(match_result)==1:
                
        planA_clothes_img_A, planA_clothes_img_B, planA_match_reason = set_image(match_result, 0)
 
    return planA_clothes_img_A, planA_clothes_img_B, planA_match_reason, planB_clothes_img_A, planB_clothes_img_B, planB_match_reason, match_result, body_shape_descs  
    # return planA_clothes_img_A, planA_clothes_img_B, planA_match_reason, planB_clothes_img_A, planB_clothes_img_B, planB_match_reason

def run_local_tryon(weather, season, determine, additional_requirements, full_body_image):
   
    try:
        opt = parse_opt(vlm_weight_name, llm_weight_name)
        interface = Interface(**vars(opt))
        # opt = parse_opt(vlm_weight_name, llm_weight_name)
        # interface = Interface(**vars(opt))
        # func="match"
        # clothes_path = "/group_share/data_org/test_data/dresses/images/024193_1.jpg"
  
        # while Cycles<total:
        
        planA_clothes_img_A = Image.new("RGB", (500, 300), 'white')
        planA_clothes_img_B = Image.new("RGB", (500, 300), 'white')
        planB_clothes_img_A = Image.new("RGB", (500, 300), 'white')
        planB_clothes_img_B = Image.new("RGB", (500, 300), 'white')
        # planC_clothes_img_A = Image.new("RGB", (500, 300), 'white')
        # planC_clothes_img_B = Image.new("RGB", (500, 300), 'white')
        planA_match_reason = ""
        planB_match_reason = ""
        # planC_match_reason = ""
        planA_try_on = Image.new("RGB", (500, 300), 'white')
        planB_try_on = Image.new("RGB", (500, 300), 'white')
        # planC_try_on = Image.new("RGB", (500, 300), 'white')
        
        
        # print("full_body_image mode-------------", full_body_image["composite"].mode)
        full_body_image = cc(full_body_image["composite"])
        # print("full_body_image mode-------------", full_body_image.mode)
        
        match_result, _ = interface.try_on_interface(weather,
        season,
        determine,
        full_body_image,
        additional_requirements)

        if len(match_result)==3:
            planA_clothes_img_A, planA_clothes_img_B, planA_match_reason, planA_try_on = set_image_try_on(match_result, 0)
            planB_clothes_img_A, planB_clothes_img_B, planB_match_reason, planB_try_on = set_image_try_on(match_result, 1)
            # planC_clothes_img_A, planC_clothes_img_B, planC_match_reason, planC_try_on = set_image_try_on(match_reslult, 2)

        elif len(match_result)==2:
            planA_clothes_img_A, planA_clothes_img_B, planA_match_reason, planA_try_on = set_image_try_on(match_result, 0)
            planB_clothes_img_A, planB_clothes_img_B, planB_match_reason, planB_try_on = set_image_try_on(match_result, 1)
                    
        elif len(match_result)==1:
            planA_clothes_img_A, planA_clothes_img_B, planA_match_reason, planA_try_on = set_image_try_on(match_result, 0)
                # torch.cuda.synchronize()
                # torch.cuda.empty_cache()
        return planA_clothes_img_A, planA_clothes_img_B, planA_match_reason, planB_clothes_img_A, planB_clothes_img_B, planB_match_reason, planA_try_on, planB_try_on
    
    except Exception as e:
 
        print(f"error: {e}, try again...")
       
    

def run_local_tryon_only(full_body_image, match_result, body_shape_descs):
    # opt = parse_opt(vlm_weight_name, llm_weight_name)
    # interface = Interface(**vars(opt))
    # func="match"
    # clothes_path = "/group_share/data_org/test_data/dresses/images/024193_1.jpg"
    # planA_clothes_img_A = Image.new("RGB", (500, 300), 'white')
    # planA_clothes_img_B = Image.new("RGB", (500, 300), 'white')
    # planB_clothes_img_A = Image.new("RGB", (500, 300), 'white')
    # planB_clothes_img_B = Image.new("RGB", (500, 300), 'white')
    # planC_clothes_img_A = Image.new("RGB", (500, 300), 'white')
    # planC_clothes_img_B = Image.new("RGB", (500, 300), 'white')
    # planA_match_reason = ""
    # planB_match_reason = ""
    # planC_match_reason = ""
    planA_try_on = Image.new("RGB", (500, 300), 'white')
    planB_try_on = Image.new("RGB", (500, 300), 'white')
    # planC_try_on = Image.new("RGB", (500, 300), 'white')
    
    
    # print("full_body_image mode-------------", full_body_image["composite"].mode)
    full_body_image = cc(full_body_image["composite"])
    # print("full_body_image mode-------------", full_body_image.mode)
    if(len(match_result) < 1):
        return planA_try_on, planB_try_on
        
    try_on_result= interface.try_on_only_interface(match_result, full_body_image, body_shape_descs)

    if len(try_on_result)==3:
        planA_try_on = set_image_try_on(try_on_result, 0)
        planB_try_on = set_image_try_on(try_on_result, 1)
        # planC_try_on = set_image_try_on(try_on_result, 2)
  
    elif len(try_on_result)==2:
        planA_try_on = set_image_try_on(try_on_result, 0)
        planB_try_on = set_image_try_on(try_on_result, 1)
        
    elif len(try_on_result)==1:
        planA_try_on = set_image_try_on(try_on_result, 0)

    return planA_try_on, planB_try_on


def run_local_wardrobe(clothes_path, category_input):
    opt = parse_opt(vlm_weight_name, llm_weight_name)
    interface = Interface(**vars(opt))
    # func="match"
    # clothes_path = "/group_share/data_org/test_data/dresses/images/024193_1.jpg"
    # planA = Image.new("RGB", (500, 300), 'white')
    # planB = Image.new("RGB", (500, 300), 'white')
    # planC = Image.new("RGB", (500, 300), 'white')
    category = ""
    caption_string = ""
    
    # upper_list = os.listdir(os.path.join(example_path,"DressCode/upper_body/images/"))
    # upper_list_path = [os.path.join(example_path,"DressCode/upper_body/images/",garm) for garm in upper_list]

    # lower_list = os.listdir(os.path.join(example_path,"DressCode/upper_body/images/"))
    # lower_list_path = [os.path.join(example_path,"DressCode/upper_body/images/",garm) for garm in lower_list]

    # dresses_list = os.listdir(os.path.join(example_path,"DressCode/upper_body/images/"))
    # dresses_list_path = [os.path.join(example_path,"DressCode/upper_body/images/",garm) for garm in dresses_list]
    #1.get caption
    caption_json, caption_string = interface.caption_interface(clothes_path)
    
    category = caption_json["category"]
    
    #2.write database(TODO)
    
    
    return category, caption_string


def is_upload():
    global interactive_
    interactive_ = True
    return interactive_

if __name__ == '__main__':

    example_path = os.environ.get('DATA_ROOT')
    upper_body = os.listdir(os.path.join(example_path,"upper_body/images/"))[:7]
    upper_body_path = [os.path.join(example_path,"upper_body/images/",human) for human in upper_body]
    human_list = os.listdir(os.path.join(example_path,"fullbody/images/"))
    human_list_path = [os.path.join(example_path,"fullbody/images/",human) for human in human_list]
    # match_reslult = []
        
    image_blocks = gr.Blocks().queue()
    
    with image_blocks as Match:
        state_session_id = gr.State(0)

        gr.Markdown("## ðŸŒŸðŸ‘—ðŸ’„ ç¾Žå¦†è¾¾äºº - ç¾Žä¸½æ‚¨çš„æ¯ä¸€å¤© ðŸ’„ðŸ‘—ðŸŒŸ")
        gr.Markdown("å› ä¸ºç®—åŠ›çš„é—®é¢˜ï¼Œç›®å‰ä¸Šä¼ ä¸€ä¸ªç®€åŒ–ç‰ˆæœ¬ã€‚å¦‚æžœæ‚¨æƒ³ä½“éªŒå®Œæ•´çš„åŠŸèƒ½ï¼Œè¯·ç§»æ­¥Githubå¹¶æŒç»­å…³æ³¨æˆ‘ä»¬çš„åŽç»­å·¥ä½œã€‚Githubï¼š[source codes](https://github.com/RayTang88/BeautyMaster), æ¬¢è¿ŽstarðŸŒŸ")
        gr.Markdown("ä½¿ç”¨æ–¹æ³•ï¼šåœ¨ç¾Žå¦†æ­é…é¡µé¢æŒ‰ç¤ºä¾‹ä¸Šä¼ ä¸€å¼ å…¨èº«ç…§ï¼Œç‚¹å‡»MatchæŒ‰é’®ï¼Œæ¨¡åž‹ä¼šç»™å‡ºç©¿æ­å»ºè®®å¹¶ä¸ºæ‚¨è¯•ç©¿å±•ç¤ºã€‚ç›®å‰æˆ‘ä»¬å†…ç½®äº†ç²¾ç®€çš„æœé¥°æ•°æ®åº“ä¾›åŸºç¡€æ•ˆæžœå±•ç¤ºã€‚å¦‚ä½¿ç”¨è¿‡ç¨‹ä¸­å‡ºçŽ°é”™è¯¯æç¤ºï¼Œè¯·é‡å¤å‰é¢çš„æ­¥éª¤ï¼Œæ„Ÿè°¢æ‚¨çš„ä½¿ç”¨ï¼")
        
        with gr.Row():
            with gr.Column():
                fullbody_img = gr.ImageEditor(sources='upload', type="pil", label='Human. Mask with pen or use auto-masking', interactive=True)
                with gr.Row():
                    with gr.Row():
                        is_checked = gr.Checkbox(label="Yes", info="Use auto-generated mask (Takes 5 seconds)",value=True)
                    with gr.Row():
                        is_checked_crop = gr.Checkbox(label="Yes", info="Use auto-crop & resizing",value=False)
                # fullbody_img = gr.Image(label="fullbody", sources='upload', type="pil")
                with gr.Row():
                    with gr.Row():
                        season = gr.Dropdown(choices=["æ˜¥å­£","å¤å­£","ç§‹å­£","å†¬å­£"], label="å­£èŠ‚", value="å¤å­£")
                    with gr.Row():
                        weather = gr.Dropdown(choices=["é›¶ä¸‹10æ‘„æ°åº¦å·¦å³","0æ‘„æ°åº¦å·¦å³","10æ‘„æ°åº¦å·¦å³","20æ‘„æ°åº¦å·¦å³","30æ‘„æ°åº¦å·¦å³", "40æ‘„æ°åº¦å·¦å³"], label="æ¸©åº¦", value="40æ‘„æ°åº¦å·¦å³")
                    with gr.Row():
                        determine = gr.Dropdown(choices=["çº¦ä¼š","é€›è¡—","æ™šå®´","å·¥ä½œ"], label="ç›®çš„", value="é€›è¡—")
                    with gr.Row():
                        additional_requirements = gr.Dropdown(choices=["å¤å¤æ€€æ—§","æ—¶å°šå‰å«","æ´»åŠ›è¿åŠ¨","ä¼˜é›…çŸ¥æ€§"], label="æ‚¨çš„ä¸ªæ€§æ­é…éœ€æ±‚", value="æ—¶å°šå‰å«")    
                # additional_requirements = gr.Textbox(placeholder="æè¿°æ‚¨å¯¹æ­é…çš„ç‰¹æ®Šéœ€æ±‚ ex) ç®€æ´å¤§æ–¹ï¼Œç¾Žä¸½åŠ¨äºº", show_label=True, label="æ‚¨çš„ä¸ªæ€§æ­é…éœ€æ±‚", elem_id="prompt")

                example = gr.Examples(
                    inputs=fullbody_img,
                    examples_per_page=10,
                    examples=human_list_path
                )

            with gr.Column():
                with gr.Row():
                    with gr.Column(elem_id="prompt-container"):
                        gr.Markdown("æŽ¨èæ–¹æ¡ˆ 1")
                    planA_clothes_img_A = gr.Image(label="Garment", sources='upload', type="pil", height=300)
                    planA_clothes_img_B = gr.Image(label="Garment", sources='upload', type="pil", height=300)
                    with gr.Row(elem_id="prompt-container"):
                        with gr.Row():
                            planA_match_reason = gr.Textbox(placeholder="", label="æŽ¨èç†ç”±", show_label=True, elem_id="planA_match_reason")
                with gr.Row():
                    with gr.Column(elem_id="prompt-container"):
                        gr.Markdown("æŽ¨èæ–¹æ¡ˆ 2")
                    planB_clothes_img_A = gr.Image(label="Garment", sources='upload', type="pil", height=300)
                    planB_clothes_img_B = gr.Image(label="Garment", sources='upload', type="pil", height=300)
                    with gr.Row(elem_id="prompt-container"):
                        with gr.Row():
                            planB_match_reason = gr.Textbox(placeholder="", label="æŽ¨èç†ç”±", show_label=True, elem_id="planB_match_reason")
                # with gr.Row():
                #     with gr.Column(elem_id="prompt-container"):
                #         gr.Markdown("æŽ¨èæ–¹æ¡ˆ 3")
                #     planC_clothes_img_A = gr.Image(label="Garment", sources='upload', type="pil", height=300)
                #     planC_clothes_img_B = gr.Image(label="Garment", sources='upload', type="pil", height=300)      
                #     with gr.Row(elem_id="prompt-container"):
                #         with gr.Row():
                #             planC_match_reason = gr.Textbox(placeholder="", label="æŽ¨èç†ç”±", show_label=True, elem_id="planC_match_reason")
                            
            with gr.Column():
                # image_out = gr.Image(label="Output", elem_id="output-img", height=400)
                planA = gr.Image(label="è¯•ç©¿å±•ç¤º 1", elem_id="Mach_output_A",show_share_button=False)
                # image_out = gr.Image(label="Output", elem_id="output-img", height=400)
                planB = gr.Image(label="è¯•ç©¿å±•ç¤º 2", elem_id="Mach_output_B",show_share_button=False)
                # image_out = gr.Image(label="Output", elem_id="output-img", height=400)
                # planC = gr.Image(label="è¯•ç©¿å±•ç¤º 3", elem_id="Mach_output_C",show_share_button=False)
                

        with gr.Row():
            with gr.Row():

                # match_button = gr.Button(value="step-1.Match", interactive=True)
                tryon_button = gr.Button(value="Match", interactive=True)
                # reset_button = gr.Button(value="Reset", interactive=True)
            # with gr.Accordion(label="Advanced Settings", open=False):
            #     with gr.Row():
            #         denoise_steps = gr.Number(label="Denoising Steps", minimum=20, maximum=40, value=30, step=1)
            #         seed = gr.Number(label="Seed", minimum=-1, maximum=2147483647, step=1, value=42)
        # match_button.click(run_local, inputs=[weather, season, determine, additional_requirements, fullbody_img], outputs=[planA_clothes_img_A, planA_clothes_img_B, planA_match_reason, planB_clothes_img_A, planB_clothes_img_B, planB_match_reason, planC_clothes_img_A, planC_clothes_img_B, planC_match_reason], api_name='Match')
        # match_result = gr.State([])
        # body_shape_descs = gr.State('')
        
        # match_button.click(run_local_match, inputs=[weather, season, determine, additional_requirements, fullbody_img], outputs=[planA_clothes_img_A, planA_clothes_img_B, planA_match_reason, planB_clothes_img_A, planB_clothes_img_B, planB_match_reason, match_result, body_shape_descs], api_name='Match')
        # match_button.click(run_local_match, inputs=[weather, season, determine, additional_requirements, fullbody_img], outputs=[planA_clothes_img_A, planA_clothes_img_B, planA_match_reason, planB_clothes_img_A, planB_clothes_img_B, planB_match_reason], api_name='Match')
        tryon_button.click(run_local_tryon, inputs=[weather, season, determine, additional_requirements, fullbody_img], outputs=[planA_clothes_img_A, planA_clothes_img_B, planA_match_reason, planB_clothes_img_A, planB_clothes_img_B, planB_match_reason, planA, planB], api_name='TryOn')
        # tryon_button.click(run_local_tryon_only, inputs=[fullbody_img, match_result, body_shape_descs], outputs=[planA, planB], api_name='TryOn')
        

    image_blocks = gr.Blocks().queue()
    with image_blocks as Wardrobe:
        gr.Markdown("è¿™é‡Œæ˜¯æ‚¨çš„ç¾Žä¸½è¡£æ©±ï¼Œæ‚¨å¯ä»¥å°†æƒ³è¦æ­é…çš„æœé¥°ä¸Šä¼ åˆ°è¿™é‡Œã€‚")
        with gr.Row():
            with gr.Column():        
                clothes_img = gr.Image(label="Garment", sources='upload', type="pil")
                with gr.Row(elem_id="prompt-container"):
                    with gr.Row():
                        category_input = gr.Dropdown(choices=["ä¸Šè¡£","è£¤å­","åŠèº«è£™","è¿žè¡£è£™", "å…¶ä»–"], label="ç±»åˆ«", value="è¿žè¡£è£™")
                        prompt = gr.Textbox(placeholder="", label="", show_label=False, elem_id="prompt")
                        
                with gr.Row(elem_id="prompt-container"):
                    with gr.Row():
                        category = gr.Textbox(placeholder="", label="ç±»åˆ«", show_label=True, elem_id="prompt")
                        caption = gr.Textbox(placeholder="", label="æ–‡å­—è¯´æ˜Ž", show_label=True, elem_id="prompt")
            
                example = gr.Examples(
                    inputs=clothes_img,
                    examples_per_page=8,
                    examples=upper_body_path)
    
                
        with gr.Column():
            wardrobe_button = gr.Button(value="Put it in matching wardrobe(coming soon...)")
            # with gr.Accordion(label="Advanced Settings", open=False):
            #     with gr.Row():
            #         denoise_steps = gr.Number(label="Denoising Steps", minimum=20, maximum=40, value=30, step=1)
            #         seed = gr.Number(label="Seed", minimum=-1, maximum=2147483647, step=1, value=42)

        # wardrobe_button.click(run_local_wardrobe, inputs=[clothes_img, category_input], outputs=[category, caption], api_name='wardrobe')

    app = gr.TabbedInterface([Match, Wardrobe], ["ç¾Žå¦†æ­é…", "ç¾Žä¸½è¡£æ©±"])
    app.launch()
